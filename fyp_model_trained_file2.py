# -*- coding: utf-8 -*-
"""FYP_MODEL_TRAINED_FILE2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cubxbu_hmdgVEYN80YbFzFDAaiiPwHGB
"""

pip install --upgrade xgboost scikit-learn --quiet

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd # Add this line to import the pandas library and assign it to the alias 'pd'
data = pd.read_csv('/content/drive/MyDrive/fypwork/real data.csv')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from xgboost import XGBClassifier

data

"""# **Fruad Count**"""

from matplotlib import pyplot as plt
import seaborn as sns
data.groupby('PotentialFraud').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

data.info()

print('Printing Null Values.\n\n',data.isnull().sum())

"""# **Data Preprocessing**

Handeling Missing Values
"""

data.fillna(0, inplace=True)

date_columns = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']

for col in date_columns:
    data[col] = pd.to_datetime(data[col], errors='coerce')  # Convert to datetime, coercing invalid dates to NaT
    data[f'{col}_Day'] = data[col].dt.day
    data[f'{col}_Month'] = data[col].dt.month
    data[f'{col}_Year'] = data[col].dt.year

data.drop(columns=date_columns, inplace=True)
data.head()

for col in data.select_dtypes(include=['object']).columns:
    if col != 'PotentialFraud':
        data[col] = data[col].astype('category').cat.codes

data['PotentialFraud'] = data['PotentialFraud'].str.strip().str.capitalize()
data['PotentialFraud'] = data['PotentialFraud'].map({'Yes': 1, 'No': 0})

drop_columns = ['ClmAdmitDiagnosisCode', 'DiagnosisGroupCode',
                'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
                'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
                'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
                'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
                'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
                'ClmProcedureCode_6']

data.drop(columns=drop_columns, errors='ignore', inplace=True)

data

print(data['PotentialFraud'].value_counts())

X = data.drop(columns=['PotentialFraud'])
y = data['PotentialFraud']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)

# Resample the dataset
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Step 1: Calculate the ratio of negative to positive classes
class_counts = data['PotentialFraud'].value_counts()
ratio_of_negative_to_positive_classes = class_counts[0] / class_counts[1]
print("Ratio of Non-Fraudulent to Fraudulent Cases:", ratio_of_negative_to_positive_classes)

from xgboost import XGBClassifier

model = XGBClassifier(
    n_estimators=1500,
    learning_rate=0.062,
    max_depth=6,
    min_child_weight=2,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy)

# Retrain the model with class weighting
model = XGBClassifier(
    n_estimators=1500,
    learning_rate=0.062,
    max_depth=6,
    min_child_weight=2,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    scale_pos_weight=0.7295102982651055
)
model.fit(X_train_resampled, y_train_resampled)

# Evaluate the model
y_pred = model.predict(X_test)
print("Classification Report:\n", classification_report(y_test, y_pred))

print("\nClassification Report:\n", classification_report(y_test, y_pred))

print(model.get_booster().feature_names)

"""# **Testing**"""

fraudulent_test_data = {
    'BeneID': ['BENE11001', 'BENE11017', 'BENE11028'],
    'ClaimID': ['CLM46614', 'CLM70950', 'CLM62376'],
    'ClaimStartDt': ['4/12/2009', '10/6/2009', '8/3/2009'],
    'ClaimEndDt': ['4/18/2009', '10/12/2009', '8/7/2009'],
    'Provider': ['PRV55912', 'PRV54986', 'PRV51148'],
    'InscClaimAmtReimbursed': [26000, 8000, 6000],
    'AttendingPhysician': ['PHY390922', 'PHY402711', 'PHY346286'],
    'OperatingPhysician': [None, 'PHY402711', 'PHY405514'],
    'OtherPhysician': [None, 'PHY402711', None],
    'AdmissionDt': ['4/12/2009', '10/6/2009', '8/3/2009'],
    'DeductibleAmtPaid': [1068.0, 1068.0, 1068.0],
    'DischargeDt': ['4/18/2009', '10/12/2009', '8/7/2009'],
    'PotentialFraud': ['Yes', 'Yes', 'Yes']
}

non_fraudulent_test_data = {
    'BeneID': ['BENE11001', 'BENE11018', 'BENE11037'],
    'ClaimID': ['CLM66048', 'CLM32075', 'CLM65412'],
    'ClaimStartDt': ['8/31/2009', '1/2/2009', '8/26/2009'],
    'ClaimEndDt': ['9/2/2009', '1/7/2009', '8/29/2009'],
    'Provider': ['PRV55907', 'PRV54090', 'PRV55846'],
    'InscClaimAmtReimbursed': [5000, 8000, 3000],
    'AttendingPhysician': ['PHY318495', 'PHY412314', 'PHY363584'],
    'OperatingPhysician': ['PHY318495', 'PHY347494', 'PHY364336'],
    'OtherPhysician': [None, None, None],
    'AdmissionDt': ['8/31/2009', '1/2/2009', '8/26/2009'],
    'DeductibleAmtPaid': [1068.0, 1068.0, 1068.0],
    'DischargeDt': ['9/2/2009', '1/7/2009', '8/29/2009'],
    'PotentialFraud': ['No', 'No', 'No']
}

def Test_example(input_data):
    input_df = pd.DataFrame(input_data)

    # Fill missing values with 0
    input_df.fillna(0, inplace=True)

    # Convert date columns
    date_columns = ['ClaimStartDt', 'AdmissionDt', 'ClaimEndDt', 'DischargeDt']
    for col in date_columns:
        input_df[col] = pd.to_datetime(input_df[col], errors='coerce')
        input_df[f'{col}_Day'] = input_df[col].dt.day
        input_df[f'{col}_Month'] = input_df[col].dt.month
        input_df[f'{col}_Year'] = input_df[col].dt.year
    input_df.drop(columns=date_columns, inplace=True)

    # Drop unnecessary columns safely
    columns_to_drop = [
        'ClmAdmitDiagnosisCode', 'DiagnosisGroupCode',
        'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
        'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
        'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
        'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
        'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
        'ClmProcedureCode_6'
    ]
    input_df.drop(columns=columns_to_drop, errors='ignore', inplace=True)

    # Convert categorical variables
    for col in input_df.select_dtypes(include=['object']).columns:
        input_df[col] = input_df[col].astype('category').cat.codes

    # Ensure only the trained features are used
    trained_features = model.get_booster().feature_names
    input_df = input_df.reindex(columns=trained_features, fill_value=0)

    # Predict
    predictions = model.predict(input_df)

    # Print results for each prediction
    for pred in predictions:
        print('Fraud' if pred == 1 else 'Not Fraud')

import pandas as pd

# Convert to DataFrames
fraudulent_df = pd.DataFrame(fraudulent_test_data)
non_fraudulent_df = pd.DataFrame(non_fraudulent_test_data)

# Combine if needed
test_data = pd.concat([fraudulent_df, non_fraudulent_df], ignore_index=True)

# Test fraudulent cases
Test_example(fraudulent_test_data)

# Test non-fraudulent cases
Test_example(non_fraudulent_test_data)

"""# **Real Time Testing**"""

import pandas as pd
import pickle

from xgboost import XGBClassifier

model = XGBClassifier()
model.fit(X_train, y_train)  # Ensure the model is trained

# Save the trained model
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

# Load the trained model
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

def Test_example(input_data):
    input_df = pd.DataFrame(input_data)
    input_df.fillna(0, inplace=True)

    # Convert date columns
    date_columns = ['ClaimStartDt', 'ClaimEndDt', 'AdmissionDt', 'DischargeDt']
    for col in date_columns:
        input_df[col] = pd.to_datetime(input_df[col], errors='coerce')
        input_df[f'{col}_Day'] = input_df[col].dt.day
        input_df[f'{col}_Month'] = input_df[col].dt.month
        input_df[f'{col}_Year'] = input_df[col].dt.year
    input_df.drop(columns=date_columns, inplace=True)

    # Drop unnecessary columns safely
    columns_to_drop = [
        'ClmAdmitDiagnosisCode', 'DiagnosisGroupCode',
        'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3',
        'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', 'ClmDiagnosisCode_6',
        'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9',
        'ClmDiagnosisCode_10', 'ClmProcedureCode_1', 'ClmProcedureCode_2',
        'ClmProcedureCode_3', 'ClmProcedureCode_4', 'ClmProcedureCode_5',
        'ClmProcedureCode_6'
    ]
    input_df.drop(columns=columns_to_drop, errors='ignore', inplace=True)
    input_df = input_df.infer_objects(copy=False)
    input_df.fillna(0, inplace=True)
    # Convert categorical variables
    for col in input_df.select_dtypes(include=['object']).columns:
        input_df[col] = input_df[col].astype('category').cat.codes

    # Ensure only the trained features are used
    trained_features = model.get_booster().feature_names
    input_df = input_df.reindex(columns=trained_features, fill_value=0)

    # Predict
    prediction = model.predict(input_df)
    print('Fraud' if prediction == 1 else 'Not Fraud')

# Example test input
test_input = {
    'BeneID': ['BENE11017'],
    'ClaimID': ['CLM70950'],
    'ClaimStartDt': ['10/6/2009'],
    'ClaimEndDt': ['10/12/2009'],
    'Provider': ['PRV54986'],
    'InscClaimAmtReimbursed': [8000],
    'AttendingPhysician': ['PHY402711'],
    'OperatingPhysician': ['PHY402711'],
    'OtherPhysician': ['PHY402711'],
    'AdmissionDt': ['10/6/2009'],
    'DeductibleAmtPaid': [1068.0],
    'DischargeDt': ['10/12/2009']
}

Test_example(test_input)